{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 句子关系推断（Entailment）\n",
    "- 一次性提供2个句子给模型推断这两句话有什么含义\n",
    "\n",
    "目的：判断2句话是否有相连的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='google-bert/bert-base-chinese', vocab_size=21128, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集并处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 9600/9600 [00:00<00:00, 349243.39 examples/s]\n",
      "Filter: 100%|██████████| 1200/1200 [00:00<00:00, 126630.06 examples/s]\n",
      "Filter: 100%|██████████| 1200/1200 [00:00<00:00, 140442.12 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text'],\n",
       "         num_rows: 8130\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['text'],\n",
       "         num_rows: 1032\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text'],\n",
       "         num_rows: 1011\n",
       "     })\n",
       " }),\n",
       " {'text': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#加载数据集\n",
    "dataset = load_dataset(path='lansinuote/ChnSentiCorp')\n",
    "\n",
    "#过滤句子长度\n",
    "f = lambda x: len(x['text']) >= 40\n",
    "dataset = dataset.filter(f)\n",
    "\n",
    "#移除多余的字段\n",
    "dataset = dataset.remove_columns(['label'])\n",
    "\n",
    "dataset, dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([4, 43])\n",
      "token_type_ids torch.Size([4, 43])\n",
      "attention_mask torch.Size([4, 43])\n",
      "label torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2032"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义数据集遍历工具\n",
    "def collate_fn(data):\n",
    "    b = len(data)\n",
    "    text = [i['text'] for i in data]\n",
    "\n",
    "    #生成前后两段话分别的索引\n",
    "    s1 = list(range(b))\n",
    "    s2 = list(range(b))\n",
    "    random.shuffle(s2)\n",
    "\n",
    "    #根据索引生成label,表明两句话是否是前后相连的关系\n",
    "    label = [s1[i] == s2[i] for i in range(b)]\n",
    "\n",
    "    #取出具体的文字  在第20个字符处切分\n",
    "    s1 = [text[i][0:20] for i in s1]\n",
    "    s2 = [text[i][20:40] for i in s2]\n",
    "\n",
    "    #句子对编码\n",
    "    data = tokenizer(s1,\n",
    "                     s2,\n",
    "                     padding=True,\n",
    "                     truncation=True,\n",
    "                     max_length=50,\n",
    "                     return_tensors='pt')\n",
    "\n",
    "    #设置label\n",
    "    data['label'] = torch.LongTensor(label)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset['train'],\n",
    "                                     batch_size=4,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True,\n",
    "                                     collate_fn=collate_fn)\n",
    "\n",
    "data = next(iter(loader))\n",
    "\n",
    "for k, v in data.items():\n",
    "    print(k, v.shape)\n",
    "\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据样例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 酒 店 服 务 不 好 ， 服 务 员 态 度 生 硬 ， 特 别 是 酒 店 [SEP] 地 毯 、 卫 生 间 和 床 铺 都 很 脏 ， 我 的 孩 子 睡 了 一 [SEP]\n",
      "tensor(0)\n",
      "================\n",
      "[CLS] 我 的 孩 子 4 周 岁 又 5 个 月 了 ， 我 买 了 《 迷 宫 》 [SEP] 层 很 高 。 房 间 从 来 没 有 安 排 到 过 正 面 湖 景 的 ， [SEP]\n",
      "tensor(0)\n",
      "================\n",
      "[CLS] 从 门 面 来 看 ， 该 酒 店 就 显 得 不 够 气 派 ， 虽 然 楼 [SEP] 物 品 管 理 方 面 ， 物 品 的 清 点 不 到 位 ， 我 明 明 没 [SEP]\n",
      "tensor(0)\n",
      "================\n",
      "[CLS] 这 个 酒 店 很 烂 。 大 堂 嘈 杂 ， 房 间 设 备 陈 旧 ， [SEP] 4 岁 ， 5 岁 ， 6 岁 的 ， 因 为 她 喜 欢 走 迷 宫 ， 而 [SEP] [PAD]\n",
      "tensor(0)\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "#查看数据样例\n",
    "for input_ids, label in zip(data['input_ids'], data['label']):\n",
    "    print(tokenizer.decode(input_ids))\n",
    "    print(label)\n",
    "    print('================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义下游任务模型（Downstream Tasks by Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6777, grad_fn=<NllLossBackward0>),\n",
       " tensor([[0.4044, 0.5956],\n",
       "         [0.6440, 0.3560],\n",
       "         [0.4996, 0.5004],\n",
       "         [0.5289, 0.4711]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义模型\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #加载预训练模型\n",
    "        from transformers import AutoModel\n",
    "        self.pretrained = AutoModel.from_pretrained(\n",
    "            'google-bert/bert-base-chinese')\n",
    "\n",
    "        self.fc = torch.nn.Linear(in_features=768, out_features=2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, label=None):\n",
    "        #使用预训练模型抽取数据特征\n",
    "        with torch.no_grad():\n",
    "            last_hidden_state = self.pretrained(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids).last_hidden_state\n",
    "\n",
    "        #只取第0个词的特征做分类,这和bert模型的训练方式有关,此处不展开\n",
    "        last_hidden_state = last_hidden_state[:, 0]\n",
    "\n",
    "        #对抽取的特征只取第一个字的结果做分类即可\n",
    "        out = self.fc(last_hidden_state).softmax(dim=1)\n",
    "\n",
    "        #计算loss\n",
    "        loss = None\n",
    "        if label is not None:\n",
    "            loss = torch.nn.functional.cross_entropy(out, label)\n",
    "\n",
    "        return loss, out\n",
    "\n",
    "\n",
    "model = Model()\n",
    "\n",
    "model(**data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2032 0.7160650491714478 0.5\n",
      "10 2032 0.614642858505249 0.75\n",
      "20 2032 0.6163564324378967 0.75\n",
      "30 2032 0.496163547039032 1.0\n",
      "40 2032 0.476115345954895 1.0\n",
      "50 2032 0.7115070819854736 0.5\n",
      "60 2032 0.5616160035133362 0.75\n",
      "70 2032 0.5783414244651794 0.5\n",
      "80 2032 0.42220208048820496 1.0\n",
      "90 2032 0.38469523191452026 1.0\n",
      "100 2032 0.4045517146587372 1.0\n",
      "110 2032 0.3656919002532959 1.0\n",
      "120 2032 0.43291038274765015 1.0\n",
      "130 2032 0.4087420701980591 1.0\n",
      "140 2032 0.45405665040016174 0.75\n",
      "150 2032 0.5398662090301514 0.75\n",
      "160 2032 0.44411206245422363 0.75\n",
      "170 2032 0.533974289894104 0.5\n",
      "180 2032 0.46027106046676636 1.0\n",
      "190 2032 0.3544018268585205 1.0\n",
      "200 2032 0.391356885433197 1.0\n",
      "210 2032 0.4554879069328308 1.0\n",
      "220 2032 0.3896465003490448 1.0\n",
      "230 2032 0.46633249521255493 1.0\n",
      "240 2032 0.47276103496551514 1.0\n",
      "250 2032 0.6206538677215576 0.5\n",
      "260 2032 0.3760732412338257 1.0\n",
      "270 2032 0.4522066116333008 0.75\n",
      "280 2032 0.449824720621109 0.75\n",
      "290 2032 0.6924847960472107 0.5\n",
      "300 2032 0.36266255378723145 1.0\n"
     ]
    }
   ],
   "source": [
    "#执行训练\n",
    "def train():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        loss, out = model(**data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            out = out.argmax(dim=1)\n",
    "            acc = (out == data.label).sum().item() / len(data.label)\n",
    "            print(i, len(loader), loss.item(), acc)\n",
    "\n",
    "        if i == 300:\n",
    "            break\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 252 1.0\n",
      "1 252 1.0\n",
      "2 252 1.0\n",
      "3 252 0.9375\n",
      "4 252 0.95\n",
      "5 252 0.9166666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#执行测试\n",
    "def test():\n",
    "    loader_test = torch.utils.data.DataLoader(dataset['test'],\n",
    "                                              batch_size=4,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True,\n",
    "                                              collate_fn=collate_fn)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(loader_test):\n",
    "        with torch.no_grad():\n",
    "            _, out = model(**data)\n",
    "\n",
    "        out = out.argmax(dim=1)\n",
    "        correct += (out == data.label).sum().item()\n",
    "        total += len(data.label)\n",
    "\n",
    "        print(i, len(loader_test), correct / total)\n",
    "\n",
    "        if i == 5:\n",
    "            break\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
